{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리\n",
    "\n",
    "텍스트 파일을 읽고, 영어와 프랑스어를 분리하여 토큰화한다.\n",
    "\n",
    "이후 전처리 과정을 통해서 인덱스를 부여한다.\n",
    "\n",
    "다음과 같은 특수한 인덱스 값이 있음에 주의한다.\n",
    "\n",
    "`UNK` 0\n",
    "\n",
    "`PAD` 1\n",
    "\n",
    "`SOS` 2\n",
    "\n",
    "`EOS` 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import nltk.translate.bleu_score as bleu\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "# Sung Hyeon Kim's Code (Assisted by Bong Won Jang)\n",
    "# - 2020 06 15 22:28 ☑️\n",
    "#####################################################\n",
    "\n",
    "def tokenize(path_name):\n",
    "\n",
    "    with open(path_name, 'r', encoding='utf-8') as f:\n",
    "            lines = f.read().split('\\n')\n",
    "\n",
    "    source_texts = []\n",
    "    target_texts = []\n",
    "    target_labels = []\n",
    "\n",
    "    for line in lines[:100]:\n",
    "        if not line:\n",
    "            break\n",
    "        source_text, target_text = line.split('\\t')\n",
    "        source_text = source_text.strip() \n",
    "        target_text = target_text.strip()\n",
    "                                                                        # -----------Example-----------\n",
    "        encoder_input = source_text.split()                             # ['come', 'on', '!']\n",
    "        decoder_input = (\"<sos> \" + target_text + \" <eos>\").split()     # ['<sos>', 'allez', '!', '<eos>']\n",
    "        target_label = (target_text + \" <eos>\").split()                 # ['allez', '!', '<eos>']\n",
    "\n",
    "        source_texts.append(encoder_input)\n",
    "        target_texts.append(decoder_input)\n",
    "        target_labels.append(target_label)\n",
    "\n",
    "    return source_texts, target_texts, target_labels\n",
    "\n",
    "def preprocess(tokenize_texts):\n",
    "    word2index = {}\n",
    "    index2word = {}\n",
    "\n",
    "    #################################################\n",
    "    # add unk, pad, sos, eos to dictionary in advance\n",
    "    #################################################\n",
    "\n",
    "    # word2index\n",
    "    word2index['<unk>'] = 0\n",
    "    word2index['<pad>'] = 1\n",
    "    word2index['<sos>'] = 2\n",
    "    word2index['<eos>'] = 3\n",
    "    \n",
    "    #index2word\n",
    "    index2word = {v: k for k, v in word2index.items()}\n",
    "\n",
    "    #################################################\n",
    "    # add other words to dictionary\n",
    "    #################################################\n",
    "    n_word = 4\n",
    "    for text in tokenize_texts:\n",
    "        for word in text:\n",
    "            if word not in word2index:\n",
    "                word2index[word] = n_word\n",
    "                index2word[n_word] = word\n",
    "                n_word += 1\n",
    "\n",
    "    return word2index, index2word\n",
    "\n",
    "def wordtext2indtext(word_texts, word2ind):\n",
    "    ind_texts = []\n",
    "\n",
    "    for word_text in word_texts:\n",
    "        temp_ind_text = []\n",
    "        for word in word_text:\n",
    "            temp_ind_text.append(word2ind[word])\n",
    "\n",
    "        ind_texts.append(temp_ind_text)\n",
    "        \n",
    "    return ind_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모델\n",
    "\n",
    "LSTM 셀을 사용한 Attention으로 `Encoder`, `Decoder`를 구현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "#   Encoder\n",
    "#\n",
    "#   Encoder for seq2seq model with attention mechanism\n",
    "#   This Encoder is based on a LSTM structure\n",
    "############################################\n",
    "class Encoder(nn.Module):\n",
    "\n",
    "    ############################################\n",
    "    #   __init__\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - input_size    : the size of input word vocabulary (영어 단어 사전 크기)\n",
    "    #   - hidden_size   : the size of hidden vector and cell vector\n",
    "    ############################################\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size                                                # scalar : We\n",
    "        self.hidden_size = hidden_size                                              # scalar : h\n",
    "        self.cell_size = hidden_size                                                # scalar : h\n",
    "\n",
    "        self.embedding_matrix = nn.Embedding(self.input_size, self.hidden_size)     # matrix : (We * h)\n",
    "        self.lstm = nn.LSTM(self.hidden_size, self.hidden_size)\n",
    "\n",
    "    ############################################\n",
    "    #   forward\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - word_num  : the integer number of a word (영어 단어 번호)\n",
    "    #   - hidden    : hidden vector (h_0 is zero vector)\n",
    "    #   - cell      : cell vector   (c_0 is zero vector)\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - o         : output vector\n",
    "    #   - hn        : next hidden vector   \n",
    "    #   - cn        : next cell vector\n",
    "    ############################################\n",
    "    def forward(self, word_num, hidden, cell):\n",
    "        embedding_vector = self.embedding_matrix.weight[word_num].view(1, 1, -1)            #    matrix : (1 * 1 * h)\n",
    "        o, (hn, cn) = self.lstm(embedding_vector, (hidden, cell))                           #  o matrix : (1 * 1 * h)\n",
    "                                                                                            # hn matrix : (1 * 1 * h)\n",
    "                                                                                            # cn matrix : (1 * 1 * h)\n",
    "        return o, (hn, cn)\n",
    "\n",
    "    ############################################\n",
    "    #   initHidden\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - device     : the integer number of a word\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - initial hidden vector : zero vector\n",
    "    #\n",
    "    #   아직 Pytorch 문법에서 3차원으로 구성해야 하는 이유를 모르겠습니다.\n",
    "    ############################################\n",
    "    def initHidden(self, device):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "\n",
    "    ############################################\n",
    "    #   initCell\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - device     : the integer number of a word\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - initial cell vector : zero vector\n",
    "    #\n",
    "    #   아직 Pytorch 문법에서 3차원으로 구성해야 하는 이유를 모르겠습니다.\n",
    "    ############################################\n",
    "    def initCell(self, device):\n",
    "        return torch.zeros(1, 1, self.cell_size, device=device)\n",
    "\n",
    "############################################\n",
    "#   Decoder\n",
    "#\n",
    "#   Decoder for seq2seq model with attention mechanism\n",
    "#   This Decoder is based on a LSTM structure\n",
    "############################################\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    ############################################\n",
    "    #   __init__\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - output_size   : the size of output word vocabulary (프랑스어 단어 사전 크기)\n",
    "    #   - hidden_size   : the size of hidden vector\n",
    "    #   - max_length    : the max length of output sentence\n",
    "    ############################################\n",
    "    def __init__(self, output_size, hidden_size):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.output_size = output_size                                              # scalar : Wd\n",
    "        self.hidden_size = hidden_size                                              # scalar : h\n",
    "        self.cell_size = hidden_size                                                # scalar : h\n",
    "        \n",
    "        self.embedding_matrix = nn.Embedding(self.output_size, self.hidden_size)    # matrix : (Wd * h)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size)\n",
    "\n",
    "        self.out_linear = nn.Linear(self.hidden_size * 2, self.output_size)         # eq : (1 * Wd) = (1 * 2h) x (2h * Wd)\n",
    "\n",
    "    ############################################\n",
    "    #   forward\n",
    "    #   \n",
    "    #   <parameters>                                                       <size>\n",
    "    #   - word_num  : the integer number of a word (프랑스 단어 번호)    :  scalar\n",
    "    #   - hidden    : hidden vector (h_0 is zero vector)                :  h \n",
    "    #   - cell      : cell vector   (c_0 is zero vector)                :  h\n",
    "    #   - hs        : pile of all hidden vector from encoder            :  (N * h)\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - o         : output vector\n",
    "    #   - hn        : next hidden vector   \n",
    "    #   - cn        : next cell vector\n",
    "    ############################################\n",
    "    def forward(self, word_num, hidden, cell, hs):\n",
    "        embedding_vector = self.embedding_matrix(word_num).view(1, 1, -1)       # matrix : (1 * 1 * h)\n",
    "        o, (hn, cn) = self.lstm(embedding_vector, (hidden, cell))               #  o matrix : (1 * 1 * h)\n",
    "                                                                                # hn matrix : (1 * 1 * h)\n",
    "                                                                                # cn matrix : (1 * 1 * h)               \n",
    "\n",
    "        attn_score = torch.mm(hs, hn.view(-1, 1)).view(1, -1)                   # (1 * N) = (N * h) x (h * 1) \n",
    "        attn_distr = F.softmax(attn_score)                                      # (1 * N) = softmax(1 * N)\n",
    "        attn_output = torch.mm(attn_distr, hs)                                  # (1 * h) = (1 * N) x (N * h)\n",
    "\n",
    "        y = F.softmax(self.out_linear(torch.cat((attn_output, hn.view(1, -1)), dim=1))) # (1 * output_size)\n",
    "                                                                                        # = softmax{ (1 * 2h) x (2h * Wd) }\n",
    "        return y, (hn, cn), attn_distr\n",
    "\n",
    "    ############################################\n",
    "    #   initHidden\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - device     : the integer number of a word\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - initial hidden vector : zero vector\n",
    "    #\n",
    "    #   아직 Pytorch 문법에서 3차원으로 구성해야 하는 이유를 모르겠습니다.\n",
    "    ############################################\n",
    "    def initHidden(self, device):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
    "        \n",
    "    ############################################\n",
    "    #   initCell\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - device     : the integer number of a word\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - initial cell vector : zero vector\n",
    "    #\n",
    "    #   아직 Pytorch 문법에서 3차원으로 구성해야 하는 이유를 모르겠습니다.\n",
    "    ############################################\n",
    "    def initCell(self, device):\n",
    "        return torch.zeros(1, 1, self.cell_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습\n",
    "\n",
    "앞서 구현한 모델을 이용한 학습을 실현한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length):\n",
    "    ############################################\n",
    "    #   train (Encoder, Decoder에 맞게 구현해야 함)\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - input_tensor  \n",
    "    #   - target_tensor  \n",
    "    #   - encoder       : Encoder 모듈\n",
    "    #   - decoder       : Decoder 모듈\n",
    "    #   - encoder       : Encoder Optim (SGD)\n",
    "    #   - decoder       : Decoder Optim (SGD)  \n",
    "    #   - criterion     : Loss 계산 (NLLLoss) \n",
    "    #   - max_length    : 문장의 최대 길이\n",
    "    #\n",
    "    #   <return>\n",
    "    #   - encoder       : Encoder 모듈\n",
    "    #   - decoder       : Decoder 모듈  \n",
    "    #   - loss          : loss\n",
    "    ############################################\n",
    "    SOS_token = 2\n",
    "    EOS_token = 3\n",
    "    \n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return encoder, decoder, loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSTM_trainer(source_size, target_size, hidden_size=256, source_ind_texts, target_ind_texts, target_ind_labels, max_length, iteration=1000, learning_rate=0.01):\n",
    "    ############################################\n",
    "    #   LSTM_trainer\n",
    "    #   \n",
    "    #   <parameters>\n",
    "    #   - source_size       : 영어 사전 크기\n",
    "    #   - target_size       : 프랑스어 사전 크기\n",
    "    #   - hidden_size       : 은닉 레이어 크기\n",
    "    #   - source_ind_texts  : index로 변환한 영어 문장\n",
    "    #   - target_ind_texts  : index로 변환한 프랑스어 문장\n",
    "    #   - target_ind_labels : index로 변환한 프랑스어 문장 레이블\n",
    "    #   - max_length        : index로 변환한 영어 또는 프랑스어 문장의 최대 길이\n",
    "    #   - iteration         : iteration 횟수 (기본값 1000)\n",
    "    #   - learning_rate     : learning rate (기본값 0.01)  \n",
    "    #\n",
    "    #   <return>\n",
    "    #   - encoder           : Encoder 모듈\n",
    "    #   - decoder           : Decoder 모듈  \n",
    "    ############################################\n",
    "\n",
    "    encoder = Encoder(source_size, hidden_size)\n",
    "    decoder = Decoder(target_size, hidden_size)\n",
    "    start = time.time()\n",
    "    print_loss_total = 0\n",
    "    pairs = [(torch.tensor(s, dtype=torch.long, device=device).view(-1, 1), \\\n",
    "              torch.tensor(t, dtype=torch.long, device=device).view(-1, 1)) \\\n",
    "             for s, t in zip(source_ind_texts, target_ind_labels)]\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [random.choice(pairs) for i in range(iteration)]\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    for i in range(iteration):\n",
    "        training_pair = training_pairs[i]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        encoder, decoder, loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion, max_length)\n",
    "        print_loss_total += loss\n",
    "\n",
    "        if iter % 100 == 0:\n",
    "            print_loss_avg = print_loss_total / 100\n",
    "            print_loss_total = 0\n",
    "            print(\"{} / {}\\n소요 시간: {}\\n진행률: {}%\\n 평균 손실: {}\".format(iter, iteration, time.time() - start, iter / iteration * 100, print_loss_avg))\n",
    "            \n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 평가\n",
    "\n",
    "학습이 잘 되었는지 `bleu score`을 이용해 평가한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_evaluate(encoder, decoder):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5673740569387403"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp1 = ['It', 'is', 'a', 'guide', 'to', 'action', 'which', 'ensures', 'that', 'the', 'military', 'always', 'obeys', 'the', 'commands', 'of', 'the', 'party']\n",
    "ref1a = ['It', 'is', 'a', 'guide', 'to', 'action', 'that', 'ensures', 'that', 'the', 'military', 'will', 'forever', 'heed', 'Party', 'commands']\n",
    "ref1b = ['It', 'is', 'the', 'guiding', 'principle', 'which', 'guarantees', 'the', 'military', 'forces', 'always', 'being', 'under', 'the', 'command', 'of', 'the', 'Party']\n",
    "ref1c = ['It', 'is', 'the', 'practical', 'guide', 'for', 'the', 'army', 'always', 'to', 'heed', 'the', 'directions', 'of', 'the', 'party']\n",
    "hyp2 = ['he', 'read', 'the', 'book', 'because', 'he', 'was', 'interested', 'in', 'world', 'history']\n",
    "ref2a = ['he', 'was', 'interested', 'in', 'world', 'history', 'because', 'he', 'read', 'the', 'book']\n",
    "\n",
    "bleu.corpus_bleu([[ref1a, ref1b], [ref2a]], [hyp1, hyp2])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 메인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1) ENG : ['go', '.'] \n",
      "(2) FRA : ['<sos>', 'va', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['va', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', '!'] \n",
      "(2) FRA : ['<sos>', 'a', 'l', 'aide', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['a', 'l', 'aide', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['stop', '!'] \n",
      "(2) FRA : ['<sos>', 'ca', 'suffit', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['ca', 'suffit', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['stop', '!'] \n",
      "(2) FRA : ['<sos>', 'stop', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['stop', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['stop', '!'] \n",
      "(2) FRA : ['<sos>', 'arrete', 'toi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['arrete', 'toi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'poursuis', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['poursuis', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'continuez', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['continuez', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'poursuivez', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['poursuivez', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'see', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'comprends', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'comprends', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'try', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'essaye', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'essaye', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'won', '!'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'gagne', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'gagne', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'won', '!'] \n",
      "(2) FRA : ['<sos>', 'je', 'l', 'ai', 'emporte', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'l', 'ai', 'emporte', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'gagne', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'gagne', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'up', '.'] \n",
      "(2) FRA : ['<sos>', 'leve', 'toi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['leve', 'toi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'now', '.'] \n",
      "(2) FRA : ['<sos>', 'va', 'maintenant', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['va', 'maintenant', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'now', '.'] \n",
      "(2) FRA : ['<sos>', 'allez', 'y', 'maintenant', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['allez', 'y', 'maintenant', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'now', '.'] \n",
      "(2) FRA : ['<sos>', 'vas', 'y', 'maintenant', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['vas', 'y', 'maintenant', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['got', 'it', '!'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'pige', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'pige', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['got', 'it', '!'] \n",
      "(2) FRA : ['<sos>', 'compris', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['compris', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['got', 'it', '?'] \n",
      "(2) FRA : ['<sos>', 'pige', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['pige', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['got', 'it', '?'] \n",
      "(2) FRA : ['<sos>', 'compris', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['compris', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['got', 'it', '?'] \n",
      "(2) FRA : ['<sos>', 't', 'as', 'capte', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['t', 'as', 'capte', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'know', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'sais', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'sais', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'ans', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'ans', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['really', '?'] \n",
      "(2) FRA : ['<sos>', 'vraiment', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['vraiment', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['really', '?'] \n",
      "(2) FRA : ['<sos>', 'vrai', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['vrai', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['really', '?'] \n",
      "(2) FRA : ['<sos>', 'ah', 'bon', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['ah', 'bon', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'try', '.'] \n",
      "(2) FRA : ['<sos>', 'on', 'essaye', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['on', 'essaye', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'nous', 'avons', 'gagne', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['nous', 'avons', 'gagne', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'nous', 'gagnames', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['nous', 'gagnames', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'nous', 'l', 'avons', 'emporte', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['nous', 'l', 'avons', 'emporte', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'nous', 'l', 'emportames', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['nous', 'l', 'emportames', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'in', '.'] \n",
      "(2) FRA : ['<sos>', 'entrez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['entrez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'in', '.'] \n",
      "(2) FRA : ['<sos>', 'entre', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['entre', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'in', '.'] \n",
      "(2) FRA : ['<sos>', 'entre', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['entre', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'in', '.'] \n",
      "(2) FRA : ['<sos>', 'entrez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['entrez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'allez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['allez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'viens', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['viens', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['come', 'on', '.'] \n",
      "(2) FRA : ['<sos>', 'venez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['venez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'va', 'chercher', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['va', 'chercher', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'out', '!'] \n",
      "(2) FRA : ['<sos>', 'sortez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['sortez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'out', '!'] \n",
      "(2) FRA : ['<sos>', 'sors', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['sors', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'out', '!'] \n",
      "(2) FRA : ['<sos>', 'sortez', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['sortez', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'out', '.'] \n",
      "(2) FRA : ['<sos>', 'sors', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['sors', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['get', 'out', '.'] \n",
      "(2) FRA : ['<sos>', 'casse', 'toi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['casse', 'toi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'home', '.'] \n",
      "(2) FRA : ['<sos>', 'rentrez', 'a', 'la', 'maison', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['rentrez', 'a', 'la', 'maison', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'home', '.'] \n",
      "(2) FRA : ['<sos>', 'rentre', 'a', 'la', 'maison', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['rentre', 'a', 'la', 'maison', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'home', '.'] \n",
      "(2) FRA : ['<sos>', 'rentre', 'chez', 'toi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['rentre', 'chez', 'toi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['go', 'home', '.'] \n",
      "(2) FRA : ['<sos>', 'rentrez', 'chez', 'vous', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['rentrez', 'chez', 'vous', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'me', '!'] \n",
      "(2) FRA : ['<sos>', 'aide', 'moi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['aide', 'moi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'me', '.'] \n",
      "(2) FRA : ['<sos>', 'aide', 'moi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['aide', 'moi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'me', '.'] \n",
      "(2) FRA : ['<sos>', 'aidez', 'moi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['aidez', 'moi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'us', '.'] \n",
      "(2) FRA : ['<sos>', 'aidez', 'nous', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['aidez', 'nous', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'us', '.'] \n",
      "(2) FRA : ['<sos>', 'aide', 'nous', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['aide', 'nous', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'll', 'go', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'irai', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'irai', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'suis', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'suis', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['it', 's', 'me', '!'] \n",
      "(2) FRA : ['<sos>', 'c', 'est', 'bibi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['c', 'est', 'bibi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['see', 'you', '.'] \n",
      "(2) FRA : ['<sos>', 'a', 'plus', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['a', 'plus', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['tell', 'me', '.'] \n",
      "(2) FRA : ['<sos>', 'dis', 'moi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['dis', 'moi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['tell', 'me', '.'] \n",
      "(2) FRA : ['<sos>', 'dites', 'moi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['dites', 'moi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['tom', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'tom', 'a', 'gagne', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['tom', 'a', 'gagne', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['we', 'know', '.'] \n",
      "(2) FRA : ['<sos>', 'nous', 'savons', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['nous', 'savons', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['be', 'still', '.'] \n",
      "(2) FRA : ['<sos>', 'sois', 'calme', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['sois', 'calme', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['be', 'still', '.'] \n",
      "(2) FRA : ['<sos>', 'soyez', 'calme', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['soyez', 'calme', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['be', 'still', '.'] \n",
      "(2) FRA : ['<sos>', 'soyez', 'calmes', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['soyez', 'calmes', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'aide', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['aide', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['help', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'aidez', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['aidez', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'did', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'l', 'ai', 'fait', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'l', 'ai', 'fait', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'did', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'c', 'est', 'moi', 'qui', 'l', 'ai', 'fait', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['c', 'est', 'moi', 'qui', 'l', 'ai', 'fait', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'get', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'compris', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'compris', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'got', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'compris', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'compris', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'got', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'ai', 'capte', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'ai', 'capte', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'll', 'try', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'vais', 'essayer', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'vais', 'essayer', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'll', 'try', '.'] \n",
      "(2) FRA : ['<sos>', 'j', 'essaierai', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['j', 'essaierai', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'back', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'suis', 'revenu', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'suis', 'revenu', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'back', '.'] \n",
      "(2) FRA : ['<sos>', 'me', 'revoila', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['me', 'revoila', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'home', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'suis', 'chez', 'moi', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'suis', 'chez', 'moi', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'well', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'vais', 'bien', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'vais', 'bien', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['i', 'm', 'well', '.'] \n",
      "(2) FRA : ['<sos>', 'je', 'me', 'porte', 'bien', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['je', 'me', 'porte', 'bien', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['it', 's', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'c', 'est', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['c', 'est', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['leave', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'laisse', 'tomber', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['laisse', 'tomber', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['leave', 'it', '.'] \n",
      "(2) FRA : ['<sos>', 'laissez', 'tomber', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['laissez', 'tomber', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['leave', 'me', '.'] \n",
      "(2) FRA : ['<sos>', 'laissez', 'moi', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['laissez', 'moi', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['leave', 'us', '.'] \n",
      "(2) FRA : ['<sos>', 'laisse', 'nous', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['laisse', 'nous', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['leave', 'us', '.'] \n",
      "(2) FRA : ['<sos>', 'laissez', 'nous', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['laissez', 'nous', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['look', 'out', '!'] \n",
      "(2) FRA : ['<sos>', 'attention', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['attention', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['look', 'out', '!'] \n",
      "(2) FRA : ['<sos>', 'regarde', 'donc', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['regarde', 'donc', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['may', 'i', 'go', '?'] \n",
      "(2) FRA : ['<sos>', 'puis', 'je', 'partir', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['puis', 'je', 'partir', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['may', 'i', 'go', '?'] \n",
      "(2) FRA : ['<sos>', 'puis', 'je', 'y', 'aller', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['puis', 'je', 'y', 'aller', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['may', 'i', 'go', '?'] \n",
      "(2) FRA : ['<sos>', 'puis', 'je', 'm', 'y', 'rendre', '?', '<eos>'] \n",
      "(3) LABEL FRA : ['puis', 'je', 'm', 'y', 'rendre', '?', '<eos>'] \n",
      "\n",
      "(1) ENG : ['stop', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'arrete', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['arrete', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['stop', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'stoppez', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['stoppez', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['tell', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'dis', 'le', 'a', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['dis', 'le', 'a', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['tell', 'tom', '.'] \n",
      "(2) FRA : ['<sos>', 'informez', 'en', 'tom', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['informez', 'en', 'tom', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['they', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'ils', 'gagnerent', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['ils', 'gagnerent', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['they', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'elles', 'gagnerent', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['elles', 'gagnerent', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['they', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'ils', 'ont', 'gagne', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['ils', 'ont', 'gagne', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['they', 'won', '.'] \n",
      "(2) FRA : ['<sos>', 'elles', 'ont', 'gagne', '.', '<eos>'] \n",
      "(3) LABEL FRA : ['elles', 'ont', 'gagne', '.', '<eos>'] \n",
      "\n",
      "(1) ENG : ['try', 'this', '.'] \n",
      "(2) FRA : ['<sos>', 'essaie', 'ceci', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['essaie', 'ceci', '!', '<eos>'] \n",
      "\n",
      "(1) ENG : ['try', 'this', '.'] \n",
      "(2) FRA : ['<sos>', 'essayez', 'ceci', '!', '<eos>'] \n",
      "(3) LABEL FRA : ['essayez', 'ceci', '!', '<eos>'] \n",
      "\n",
      "------------------------------------\n",
      "SIZE source_word2index :  45\n",
      "[('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('go', 4), ('.', 5), ('help', 6), ('!', 7), ('stop', 8), ('on', 9), ('i', 10), ('see', 11), ('try', 12), ('won', 13), ('get', 14), ('up', 15), ('now', 16), ('got', 17), ('it', 18), ('?', 19), ('know', 20), ('m', 21), ('really', 22), ('we', 23), ('come', 24), ('in', 25), ('tom', 26), ('out', 27), ('home', 28), ('me', 29), ('us', 30), ('ll', 31), ('s', 32), ('you', 33), ('tell', 34), ('be', 35), ('still', 36), ('did', 37), ('back', 38), ('well', 39), ('leave', 40), ('look', 41), ('may', 42), ('they', 43), ('this', 44)]\n",
      "[(0, '<unk>'), (1, '<pad>'), (2, '<sos>'), (3, '<eos>'), (4, 'go'), (5, '.'), (6, 'help'), (7, '!'), (8, 'stop'), (9, 'on'), (10, 'i'), (11, 'see'), (12, 'try'), (13, 'won'), (14, 'get'), (15, 'up'), (16, 'now'), (17, 'got'), (18, 'it'), (19, '?'), (20, 'know'), (21, 'm'), (22, 'really'), (23, 'we'), (24, 'come'), (25, 'in'), (26, 'tom'), (27, 'out'), (28, 'home'), (29, 'me'), (30, 'us'), (31, 'll'), (32, 's'), (33, 'you'), (34, 'tell'), (35, 'be'), (36, 'still'), (37, 'did'), (38, 'back'), (39, 'well'), (40, 'leave'), (41, 'look'), (42, 'may'), (43, 'they'), (44, 'this')]\n",
      "------------------------------------\n",
      "SIZE target_word2index :  109\n",
      "[('<unk>', 0), ('<pad>', 1), ('<sos>', 2), ('<eos>', 3), ('va', 4), ('!', 5), ('a', 6), ('l', 7), ('aide', 8), ('ca', 9), ('suffit', 10), ('stop', 11), ('arrete', 12), ('toi', 13), ('poursuis', 14), ('.', 15), ('continuez', 16), ('poursuivez', 17), ('je', 18), ('comprends', 19), ('j', 20), ('essaye', 21), ('ai', 22), ('gagne', 23), ('emporte', 24), ('leve', 25), ('maintenant', 26), ('allez', 27), ('y', 28), ('vas', 29), ('pige', 30), ('compris', 31), ('?', 32), ('t', 33), ('as', 34), ('capte', 35), ('sais', 36), ('ans', 37), ('vraiment', 38), ('vrai', 39), ('ah', 40), ('bon', 41), ('on', 42), ('nous', 43), ('avons', 44), ('gagnames', 45), ('emportames', 46), ('entrez', 47), ('entre', 48), ('viens', 49), ('venez', 50), ('chercher', 51), ('tom', 52), ('sortez', 53), ('sors', 54), ('casse', 55), ('rentrez', 56), ('la', 57), ('maison', 58), ('rentre', 59), ('chez', 60), ('vous', 61), ('moi', 62), ('aidez', 63), ('irai', 64), ('suis', 65), ('c', 66), ('est', 67), ('bibi', 68), ('plus', 69), ('dis', 70), ('dites', 71), ('savons', 72), ('sois', 73), ('calme', 74), ('soyez', 75), ('calmes', 76), ('fait', 77), ('qui', 78), ('vais', 79), ('essayer', 80), ('essaierai', 81), ('revenu', 82), ('me', 83), ('revoila', 84), ('bien', 85), ('porte', 86), ('laisse', 87), ('tomber', 88), ('laissez', 89), ('attention', 90), ('regarde', 91), ('donc', 92), ('puis', 93), ('partir', 94), ('aller', 95), ('m', 96), ('rendre', 97), ('stoppez', 98), ('le', 99), ('informez', 100), ('en', 101), ('ils', 102), ('gagnerent', 103), ('elles', 104), ('ont', 105), ('essaie', 106), ('ceci', 107), ('essayez', 108)]\n",
      "[(0, '<unk>'), (1, '<pad>'), (2, '<sos>'), (3, '<eos>'), (4, 'va'), (5, '!'), (6, 'a'), (7, 'l'), (8, 'aide'), (9, 'ca'), (10, 'suffit'), (11, 'stop'), (12, 'arrete'), (13, 'toi'), (14, 'poursuis'), (15, '.'), (16, 'continuez'), (17, 'poursuivez'), (18, 'je'), (19, 'comprends'), (20, 'j'), (21, 'essaye'), (22, 'ai'), (23, 'gagne'), (24, 'emporte'), (25, 'leve'), (26, 'maintenant'), (27, 'allez'), (28, 'y'), (29, 'vas'), (30, 'pige'), (31, 'compris'), (32, '?'), (33, 't'), (34, 'as'), (35, 'capte'), (36, 'sais'), (37, 'ans'), (38, 'vraiment'), (39, 'vrai'), (40, 'ah'), (41, 'bon'), (42, 'on'), (43, 'nous'), (44, 'avons'), (45, 'gagnames'), (46, 'emportames'), (47, 'entrez'), (48, 'entre'), (49, 'viens'), (50, 'venez'), (51, 'chercher'), (52, 'tom'), (53, 'sortez'), (54, 'sors'), (55, 'casse'), (56, 'rentrez'), (57, 'la'), (58, 'maison'), (59, 'rentre'), (60, 'chez'), (61, 'vous'), (62, 'moi'), (63, 'aidez'), (64, 'irai'), (65, 'suis'), (66, 'c'), (67, 'est'), (68, 'bibi'), (69, 'plus'), (70, 'dis'), (71, 'dites'), (72, 'savons'), (73, 'sois'), (74, 'calme'), (75, 'soyez'), (76, 'calmes'), (77, 'fait'), (78, 'qui'), (79, 'vais'), (80, 'essayer'), (81, 'essaierai'), (82, 'revenu'), (83, 'me'), (84, 'revoila'), (85, 'bien'), (86, 'porte'), (87, 'laisse'), (88, 'tomber'), (89, 'laissez'), (90, 'attention'), (91, 'regarde'), (92, 'donc'), (93, 'puis'), (94, 'partir'), (95, 'aller'), (96, 'm'), (97, 'rendre'), (98, 'stoppez'), (99, 'le'), (100, 'informez'), (101, 'en'), (102, 'ils'), (103, 'gagnerent'), (104, 'elles'), (105, 'ont'), (106, 'essaie'), (107, 'ceci'), (108, 'essayez')]\n",
      "(1) ENG : [4, 5] \n",
      "(2) FRA : [2, 4, 5, 3] \n",
      "(3) LABEL FRA : [4, 5, 3] \n",
      "\n",
      "(1) ENG : [6, 7] \n",
      "(2) FRA : [2, 6, 7, 8, 5, 3] \n",
      "(3) LABEL FRA : [6, 7, 8, 5, 3] \n",
      "\n",
      "(1) ENG : [8, 7] \n",
      "(2) FRA : [2, 9, 10, 5, 3] \n",
      "(3) LABEL FRA : [9, 10, 5, 3] \n",
      "\n",
      "(1) ENG : [8, 7] \n",
      "(2) FRA : [2, 11, 5, 3] \n",
      "(3) LABEL FRA : [11, 5, 3] \n",
      "\n",
      "(1) ENG : [8, 7] \n",
      "(2) FRA : [2, 12, 13, 5, 3] \n",
      "(3) LABEL FRA : [12, 13, 5, 3] \n",
      "\n",
      "(1) ENG : [4, 9, 5] \n",
      "(2) FRA : [2, 14, 15, 3] \n",
      "(3) LABEL FRA : [14, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 9, 5] \n",
      "(2) FRA : [2, 16, 15, 3] \n",
      "(3) LABEL FRA : [16, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 9, 5] \n",
      "(2) FRA : [2, 17, 15, 3] \n",
      "(3) LABEL FRA : [17, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 11, 5] \n",
      "(2) FRA : [2, 18, 19, 15, 3] \n",
      "(3) LABEL FRA : [18, 19, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 12, 5] \n",
      "(2) FRA : [2, 20, 21, 15, 3] \n",
      "(3) LABEL FRA : [20, 21, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 13, 7] \n",
      "(2) FRA : [2, 20, 22, 23, 5, 3] \n",
      "(3) LABEL FRA : [20, 22, 23, 5, 3] \n",
      "\n",
      "(1) ENG : [10, 13, 7] \n",
      "(2) FRA : [2, 18, 7, 22, 24, 5, 3] \n",
      "(3) LABEL FRA : [18, 7, 22, 24, 5, 3] \n",
      "\n",
      "(1) ENG : [10, 13, 5] \n",
      "(2) FRA : [2, 20, 22, 23, 15, 3] \n",
      "(3) LABEL FRA : [20, 22, 23, 15, 3] \n",
      "\n",
      "(1) ENG : [14, 15, 5] \n",
      "(2) FRA : [2, 25, 13, 15, 3] \n",
      "(3) LABEL FRA : [25, 13, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 16, 5] \n",
      "(2) FRA : [2, 4, 26, 15, 3] \n",
      "(3) LABEL FRA : [4, 26, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 16, 5] \n",
      "(2) FRA : [2, 27, 28, 26, 15, 3] \n",
      "(3) LABEL FRA : [27, 28, 26, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 16, 5] \n",
      "(2) FRA : [2, 29, 28, 26, 15, 3] \n",
      "(3) LABEL FRA : [29, 28, 26, 15, 3] \n",
      "\n",
      "(1) ENG : [17, 18, 7] \n",
      "(2) FRA : [2, 20, 22, 30, 5, 3] \n",
      "(3) LABEL FRA : [20, 22, 30, 5, 3] \n",
      "\n",
      "(1) ENG : [17, 18, 7] \n",
      "(2) FRA : [2, 31, 5, 3] \n",
      "(3) LABEL FRA : [31, 5, 3] \n",
      "\n",
      "(1) ENG : [17, 18, 19] \n",
      "(2) FRA : [2, 30, 32, 3] \n",
      "(3) LABEL FRA : [30, 32, 3] \n",
      "\n",
      "(1) ENG : [17, 18, 19] \n",
      "(2) FRA : [2, 31, 32, 3] \n",
      "(3) LABEL FRA : [31, 32, 3] \n",
      "\n",
      "(1) ENG : [17, 18, 19] \n",
      "(2) FRA : [2, 33, 34, 35, 32, 3] \n",
      "(3) LABEL FRA : [33, 34, 35, 32, 3] \n",
      "\n",
      "(1) ENG : [10, 20, 5] \n",
      "(2) FRA : [2, 18, 36, 15, 3] \n",
      "(3) LABEL FRA : [18, 36, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 5] \n",
      "(2) FRA : [2, 20, 22, 37, 15, 3] \n",
      "(3) LABEL FRA : [20, 22, 37, 15, 3] \n",
      "\n",
      "(1) ENG : [22, 19] \n",
      "(2) FRA : [2, 38, 32, 3] \n",
      "(3) LABEL FRA : [38, 32, 3] \n",
      "\n",
      "(1) ENG : [22, 19] \n",
      "(2) FRA : [2, 39, 32, 3] \n",
      "(3) LABEL FRA : [39, 32, 3] \n",
      "\n",
      "(1) ENG : [22, 19] \n",
      "(2) FRA : [2, 40, 41, 32, 3] \n",
      "(3) LABEL FRA : [40, 41, 32, 3] \n",
      "\n",
      "(1) ENG : [23, 12, 5] \n",
      "(2) FRA : [2, 42, 21, 15, 3] \n",
      "(3) LABEL FRA : [42, 21, 15, 3] \n",
      "\n",
      "(1) ENG : [23, 13, 5] \n",
      "(2) FRA : [2, 43, 44, 23, 15, 3] \n",
      "(3) LABEL FRA : [43, 44, 23, 15, 3] \n",
      "\n",
      "(1) ENG : [23, 13, 5] \n",
      "(2) FRA : [2, 43, 45, 15, 3] \n",
      "(3) LABEL FRA : [43, 45, 15, 3] \n",
      "\n",
      "(1) ENG : [23, 13, 5] \n",
      "(2) FRA : [2, 43, 7, 44, 24, 15, 3] \n",
      "(3) LABEL FRA : [43, 7, 44, 24, 15, 3] \n",
      "\n",
      "(1) ENG : [23, 13, 5] \n",
      "(2) FRA : [2, 43, 7, 46, 15, 3] \n",
      "(3) LABEL FRA : [43, 7, 46, 15, 3] \n",
      "\n",
      "(1) ENG : [24, 25, 5] \n",
      "(2) FRA : [2, 47, 5, 3] \n",
      "(3) LABEL FRA : [47, 5, 3] \n",
      "\n",
      "(1) ENG : [24, 25, 5] \n",
      "(2) FRA : [2, 48, 15, 3] \n",
      "(3) LABEL FRA : [48, 15, 3] \n",
      "\n",
      "(1) ENG : [24, 25, 5] \n",
      "(2) FRA : [2, 48, 5, 3] \n",
      "(3) LABEL FRA : [48, 5, 3] \n",
      "\n",
      "(1) ENG : [24, 25, 5] \n",
      "(2) FRA : [2, 47, 5, 3] \n",
      "(3) LABEL FRA : [47, 5, 3] \n",
      "\n",
      "(1) ENG : [24, 9, 5] \n",
      "(2) FRA : [2, 27, 5, 3] \n",
      "(3) LABEL FRA : [27, 5, 3] \n",
      "\n",
      "(1) ENG : [24, 9, 5] \n",
      "(2) FRA : [2, 49, 5, 3] \n",
      "(3) LABEL FRA : [49, 5, 3] \n",
      "\n",
      "(1) ENG : [24, 9, 5] \n",
      "(2) FRA : [2, 50, 5, 3] \n",
      "(3) LABEL FRA : [50, 5, 3] \n",
      "\n",
      "(1) ENG : [14, 26, 5] \n",
      "(2) FRA : [2, 4, 51, 52, 15, 3] \n",
      "(3) LABEL FRA : [4, 51, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [14, 27, 7] \n",
      "(2) FRA : [2, 53, 5, 3] \n",
      "(3) LABEL FRA : [53, 5, 3] \n",
      "\n",
      "(1) ENG : [14, 27, 7] \n",
      "(2) FRA : [2, 54, 5, 3] \n",
      "(3) LABEL FRA : [54, 5, 3] \n",
      "\n",
      "(1) ENG : [14, 27, 7] \n",
      "(2) FRA : [2, 53, 5, 3] \n",
      "(3) LABEL FRA : [53, 5, 3] \n",
      "\n",
      "(1) ENG : [14, 27, 5] \n",
      "(2) FRA : [2, 54, 15, 3] \n",
      "(3) LABEL FRA : [54, 15, 3] \n",
      "\n",
      "(1) ENG : [14, 27, 5] \n",
      "(2) FRA : [2, 55, 13, 15, 3] \n",
      "(3) LABEL FRA : [55, 13, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 28, 5] \n",
      "(2) FRA : [2, 56, 6, 57, 58, 15, 3] \n",
      "(3) LABEL FRA : [56, 6, 57, 58, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 28, 5] \n",
      "(2) FRA : [2, 59, 6, 57, 58, 15, 3] \n",
      "(3) LABEL FRA : [59, 6, 57, 58, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 28, 5] \n",
      "(2) FRA : [2, 59, 60, 13, 15, 3] \n",
      "(3) LABEL FRA : [59, 60, 13, 15, 3] \n",
      "\n",
      "(1) ENG : [4, 28, 5] \n",
      "(2) FRA : [2, 56, 60, 61, 15, 3] \n",
      "(3) LABEL FRA : [56, 60, 61, 15, 3] \n",
      "\n",
      "(1) ENG : [6, 29, 7] \n",
      "(2) FRA : [2, 8, 62, 5, 3] \n",
      "(3) LABEL FRA : [8, 62, 5, 3] \n",
      "\n",
      "(1) ENG : [6, 29, 5] \n",
      "(2) FRA : [2, 8, 62, 15, 3] \n",
      "(3) LABEL FRA : [8, 62, 15, 3] \n",
      "\n",
      "(1) ENG : [6, 29, 5] \n",
      "(2) FRA : [2, 63, 62, 15, 3] \n",
      "(3) LABEL FRA : [63, 62, 15, 3] \n",
      "\n",
      "(1) ENG : [6, 30, 5] \n",
      "(2) FRA : [2, 63, 43, 5, 3] \n",
      "(3) LABEL FRA : [63, 43, 5, 3] \n",
      "\n",
      "(1) ENG : [6, 30, 5] \n",
      "(2) FRA : [2, 8, 43, 5, 3] \n",
      "(3) LABEL FRA : [8, 43, 5, 3] \n",
      "\n",
      "(1) ENG : [10, 31, 4, 5] \n",
      "(2) FRA : [2, 20, 64, 15, 3] \n",
      "(3) LABEL FRA : [20, 64, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 26, 5] \n",
      "(2) FRA : [2, 18, 65, 52, 15, 3] \n",
      "(3) LABEL FRA : [18, 65, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [18, 32, 29, 7] \n",
      "(2) FRA : [2, 66, 67, 68, 5, 3] \n",
      "(3) LABEL FRA : [66, 67, 68, 5, 3] \n",
      "\n",
      "(1) ENG : [11, 33, 5] \n",
      "(2) FRA : [2, 6, 69, 15, 3] \n",
      "(3) LABEL FRA : [6, 69, 15, 3] \n",
      "\n",
      "(1) ENG : [34, 29, 5] \n",
      "(2) FRA : [2, 70, 62, 5, 3] \n",
      "(3) LABEL FRA : [70, 62, 5, 3] \n",
      "\n",
      "(1) ENG : [34, 29, 5] \n",
      "(2) FRA : [2, 71, 62, 5, 3] \n",
      "(3) LABEL FRA : [71, 62, 5, 3] \n",
      "\n",
      "(1) ENG : [26, 13, 5] \n",
      "(2) FRA : [2, 52, 6, 23, 15, 3] \n",
      "(3) LABEL FRA : [52, 6, 23, 15, 3] \n",
      "\n",
      "(1) ENG : [23, 20, 5] \n",
      "(2) FRA : [2, 43, 72, 15, 3] \n",
      "(3) LABEL FRA : [43, 72, 15, 3] \n",
      "\n",
      "(1) ENG : [35, 36, 5] \n",
      "(2) FRA : [2, 73, 74, 5, 3] \n",
      "(3) LABEL FRA : [73, 74, 5, 3] \n",
      "\n",
      "(1) ENG : [35, 36, 5] \n",
      "(2) FRA : [2, 75, 74, 5, 3] \n",
      "(3) LABEL FRA : [75, 74, 5, 3] \n",
      "\n",
      "(1) ENG : [35, 36, 5] \n",
      "(2) FRA : [2, 75, 76, 5, 3] \n",
      "(3) LABEL FRA : [75, 76, 5, 3] \n",
      "\n",
      "(1) ENG : [6, 26, 5] \n",
      "(2) FRA : [2, 8, 52, 15, 3] \n",
      "(3) LABEL FRA : [8, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [6, 26, 5] \n",
      "(2) FRA : [2, 63, 52, 15, 3] \n",
      "(3) LABEL FRA : [63, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 37, 18, 5] \n",
      "(2) FRA : [2, 18, 7, 22, 77, 15, 3] \n",
      "(3) LABEL FRA : [18, 7, 22, 77, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 37, 18, 5] \n",
      "(2) FRA : [2, 66, 67, 62, 78, 7, 22, 77, 15, 3] \n",
      "(3) LABEL FRA : [66, 67, 62, 78, 7, 22, 77, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 14, 18, 5] \n",
      "(2) FRA : [2, 20, 22, 31, 15, 3] \n",
      "(3) LABEL FRA : [20, 22, 31, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 17, 18, 5] \n",
      "(2) FRA : [2, 20, 22, 31, 15, 3] \n",
      "(3) LABEL FRA : [20, 22, 31, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 17, 18, 5] \n",
      "(2) FRA : [2, 20, 22, 35, 15, 3] \n",
      "(3) LABEL FRA : [20, 22, 35, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 31, 12, 5] \n",
      "(2) FRA : [2, 18, 79, 80, 15, 3] \n",
      "(3) LABEL FRA : [18, 79, 80, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 31, 12, 5] \n",
      "(2) FRA : [2, 20, 81, 15, 3] \n",
      "(3) LABEL FRA : [20, 81, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 38, 5] \n",
      "(2) FRA : [2, 18, 65, 82, 15, 3] \n",
      "(3) LABEL FRA : [18, 65, 82, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 38, 5] \n",
      "(2) FRA : [2, 83, 84, 15, 3] \n",
      "(3) LABEL FRA : [83, 84, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 28, 5] \n",
      "(2) FRA : [2, 18, 65, 60, 62, 15, 3] \n",
      "(3) LABEL FRA : [18, 65, 60, 62, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 39, 5] \n",
      "(2) FRA : [2, 18, 79, 85, 15, 3] \n",
      "(3) LABEL FRA : [18, 79, 85, 15, 3] \n",
      "\n",
      "(1) ENG : [10, 21, 39, 5] \n",
      "(2) FRA : [2, 18, 83, 86, 85, 15, 3] \n",
      "(3) LABEL FRA : [18, 83, 86, 85, 15, 3] \n",
      "\n",
      "(1) ENG : [18, 32, 26, 5] \n",
      "(2) FRA : [2, 66, 67, 52, 15, 3] \n",
      "(3) LABEL FRA : [66, 67, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [40, 18, 5] \n",
      "(2) FRA : [2, 87, 88, 5, 3] \n",
      "(3) LABEL FRA : [87, 88, 5, 3] \n",
      "\n",
      "(1) ENG : [40, 18, 5] \n",
      "(2) FRA : [2, 89, 88, 5, 3] \n",
      "(3) LABEL FRA : [89, 88, 5, 3] \n",
      "\n",
      "(1) ENG : [40, 29, 5] \n",
      "(2) FRA : [2, 89, 62, 5, 3] \n",
      "(3) LABEL FRA : [89, 62, 5, 3] \n",
      "\n",
      "(1) ENG : [40, 30, 5] \n",
      "(2) FRA : [2, 87, 43, 5, 3] \n",
      "(3) LABEL FRA : [87, 43, 5, 3] \n",
      "\n",
      "(1) ENG : [40, 30, 5] \n",
      "(2) FRA : [2, 89, 43, 5, 3] \n",
      "(3) LABEL FRA : [89, 43, 5, 3] \n",
      "\n",
      "(1) ENG : [41, 27, 7] \n",
      "(2) FRA : [2, 90, 5, 3] \n",
      "(3) LABEL FRA : [90, 5, 3] \n",
      "\n",
      "(1) ENG : [41, 27, 7] \n",
      "(2) FRA : [2, 91, 92, 5, 3] \n",
      "(3) LABEL FRA : [91, 92, 5, 3] \n",
      "\n",
      "(1) ENG : [42, 10, 4, 19] \n",
      "(2) FRA : [2, 93, 18, 94, 32, 3] \n",
      "(3) LABEL FRA : [93, 18, 94, 32, 3] \n",
      "\n",
      "(1) ENG : [42, 10, 4, 19] \n",
      "(2) FRA : [2, 93, 18, 28, 95, 32, 3] \n",
      "(3) LABEL FRA : [93, 18, 28, 95, 32, 3] \n",
      "\n",
      "(1) ENG : [42, 10, 4, 19] \n",
      "(2) FRA : [2, 93, 18, 96, 28, 97, 32, 3] \n",
      "(3) LABEL FRA : [93, 18, 96, 28, 97, 32, 3] \n",
      "\n",
      "(1) ENG : [8, 26, 5] \n",
      "(2) FRA : [2, 12, 52, 15, 3] \n",
      "(3) LABEL FRA : [12, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [8, 26, 5] \n",
      "(2) FRA : [2, 98, 52, 15, 3] \n",
      "(3) LABEL FRA : [98, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [34, 26, 5] \n",
      "(2) FRA : [2, 70, 99, 6, 52, 15, 3] \n",
      "(3) LABEL FRA : [70, 99, 6, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [34, 26, 5] \n",
      "(2) FRA : [2, 100, 101, 52, 15, 3] \n",
      "(3) LABEL FRA : [100, 101, 52, 15, 3] \n",
      "\n",
      "(1) ENG : [43, 13, 5] \n",
      "(2) FRA : [2, 102, 103, 15, 3] \n",
      "(3) LABEL FRA : [102, 103, 15, 3] \n",
      "\n",
      "(1) ENG : [43, 13, 5] \n",
      "(2) FRA : [2, 104, 103, 15, 3] \n",
      "(3) LABEL FRA : [104, 103, 15, 3] \n",
      "\n",
      "(1) ENG : [43, 13, 5] \n",
      "(2) FRA : [2, 102, 105, 23, 15, 3] \n",
      "(3) LABEL FRA : [102, 105, 23, 15, 3] \n",
      "\n",
      "(1) ENG : [43, 13, 5] \n",
      "(2) FRA : [2, 104, 105, 23, 15, 3] \n",
      "(3) LABEL FRA : [104, 105, 23, 15, 3] \n",
      "\n",
      "(1) ENG : [12, 44, 5] \n",
      "(2) FRA : [2, 106, 107, 5, 3] \n",
      "(3) LABEL FRA : [106, 107, 5, 3] \n",
      "\n",
      "(1) ENG : [12, 44, 5] \n",
      "(2) FRA : [2, 108, 107, 5, 3] \n",
      "(3) LABEL FRA : [108, 107, 5, 3] \n",
      "\n",
      "------------------------------------\n",
      "SOURCE WORD2INDEX MAX LENGTH :  4\n",
      "TARGET WORD2INDEX MAX LENGTH :  10\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    source_texts, target_texts, target_labels = tokenize('data/eng-fra_train.txt')\n",
    "    \n",
    "    for eng, fra , label_fra in zip(source_texts, target_texts, target_labels):\n",
    "        print(\"(1) ENG :\", eng, \"\\n(2) FRA :\", fra, \"\\n(3) LABEL FRA :\", label_fra, \"\\n\")\n",
    "    \n",
    "\n",
    "    source_word2index, source_index2word = preprocess(source_texts)\n",
    "    target_word2index, target_index2word = preprocess(target_texts)\n",
    "    source_size = len(source_word2index)\n",
    "    target_size = len(target_word2index)\n",
    "\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"SIZE source_word2index : \", source_size)\n",
    "    print(list(source_word2index.items()))\n",
    "    print(list(source_index2word.items()))\n",
    "\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"SIZE target_word2index : \", target_size)\n",
    "    print(list(target_word2index.items()))\n",
    "    print(list(target_index2word.items()))\n",
    "\n",
    "    source_ind_texts = wordtext2indtext(source_texts, source_word2index)\n",
    "    target_ind_texts = wordtext2indtext(target_texts, target_word2index)\n",
    "    target_ind_labels = wordtext2indtext(target_labels, target_word2index)\n",
    "    \n",
    "    \n",
    "    for eng, fra , label_fra in zip(source_ind_texts, target_ind_texts, target_ind_labels):\n",
    "        print(\"(1) ENG :\", eng, \"\\n(2) FRA :\", fra, \"\\n(3) LABEL FRA :\", label_fra, \"\\n\")\n",
    "    \n",
    "    \n",
    "    source_max_length = max([len(each) for each in source_ind_texts])\n",
    "    target_max_length = max([len(each) for each in target_ind_texts])\n",
    "    max_length = max(source_max_length, target_max_length)\n",
    "    print(\"------------------------------------\")\n",
    "    print(\"SOURCE WORD2INDEX MAX LENGTH : \", source_max_length)\n",
    "    print(\"TARGET WORD2INDEX MAX LENGTH : \", target_max_length)\n",
    "    \n",
    "    # encoder, decoder = LSTM_trainer(source_size, target_size, hidden_size=256, source_ind_texts, target_ind_texts, target_ind_labels, max_length)\n",
    "    # random_evaluate(encoder, decoder)\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
